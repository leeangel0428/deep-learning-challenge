{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv1GnN-uqOyS"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "7bwCRSFMqOyU",
        "outputId": "b6399270-b6f3-45f0-c08c-1ba8a56e7844"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTXx-VFgqOyW"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(columns= ['EIN', 'NAME'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naw1H4VpqOyX",
        "outputId": "f95f75fd-01b4-4629-e4f0-6f517526b7ac"
      },
      "outputs": [],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5B5gv_AqOyY",
        "outputId": "bc7569f1-c6d1-47c4-b7d6-e2a05ec9202b"
      },
      "outputs": [],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPdSz0r0qOyY",
        "outputId": "71aa1d98-f35f-4435-c2d3-0d7037638df4"
      },
      "outputs": [],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_value_count = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "applications_to_replace = list(application_value_count[application_value_count<500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in applications_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejLqHyRqqOyZ",
        "outputId": "ea27d7bd-8507-443f-e570-dfac02bceda4"
      },
      "outputs": [],
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_value_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classification_value_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArwBoS_CqOya",
        "outputId": "77110dea-4dfe-4ace-e3ac-0cf5bdc7a8f5"
      },
      "outputs": [],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "classification_value_counts.loc[classification_value_counts > 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2G8VFsBqOyb",
        "outputId": "785784c3-3338-4dcc-daaf-ea7aa0c95073"
      },
      "outputs": [],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = list(classification_value_counts[classification_value_counts<1000].index)\n",
        "\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "gtYxsTFRqOyb",
        "outputId": "c9b45b11-761f-4351-f751-37b32996b84a"
      },
      "outputs": [],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "\n",
        "# List of columns names\n",
        "application_categories = [\"APPLICATION_TYPE\", \"AFFILIATION\", \"CLASSIFICATION\", \"USE_CASE\", \"ORGANIZATION\", \"INCOME_AMT\", \"SPECIAL_CONSIDERATIONS\"]\n",
        "\n",
        "#Using get_dummies to perform one-hot encoding on the specified columns\n",
        "dummies_df = pd.get_dummies(application_df[application_categories])\n",
        "\n",
        "#Merging the original df with the dummies df\n",
        "application_df = application_df.merge(dummies_df, left_index=True, right_index=True)\n",
        "\n",
        "#Dropping original categorical columns which have since been converted/replaced\n",
        "application_df = application_df.drop(application_categories, 1)\n",
        "\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9RZbYmhqOyc",
        "outputId": "2b790f5b-1c09-476d-8c44-86899f0076a2"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = application_df[\"IS_SUCCESSFUL\"]\n",
        "X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7LcK_DYqOyc"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf9JrmG9qOyc"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itXHVgWWqOyc",
        "outputId": "410a85de-785e-4622-b612-47ef7b9fc9d5"
      },
      "outputs": [],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 = 8\n",
        "hidden_nodes_layer2 = 5\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim= input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zX7io7CqOyc"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMLF6IFxqOyd",
        "outputId": "e860c881-9b11-4777-9ba4-385f9c3b2f91"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvt1w2TJqOyd",
        "outputId": "9835b060-797a-4317-a228-a70d8ad0bf2b"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fl5xXypqOyd"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "filepath= r\"C:/Users/leean/OneDrive/Data_Analytics/Data_Analytics/Projects/deep-learning-challenge\\AlphabetSoupCharity_Op.h5\"\n",
        "nn.save(filepath, save_format='h5')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.-1.-1"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
